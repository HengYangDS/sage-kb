# Expert Committee Framework

> Multi-perspective analysis using 6 domains √ó 23 roles √ó 10 categories √ó 37 angles

---

## Table of Contents

- [0. Quick Start](#0-quick-start)
- [1. First Principles](#1-first-principles)
- [2. Framework Overview](#2-framework-overview)
- [3. Committee Levels](#3-committee-levels)
- [4. Dynamic Activation](#4-dynamic-activation)
- [5. Analysis Process](#5-analysis-process)
- [6. Enhanced Aggregation](#6-enhanced-aggregation)
- [7. Uncertainty Quantification](#7-uncertainty-quantification)
- [8. Bias Correction](#8-bias-correction)
- [9. Dynamic Weight Learning](#9-dynamic-weight-learning)
- [10. Decision Effectiveness Tracking](#10-decision-effectiveness-tracking)
- [11. Quick Reference](#11-quick-reference)
- [12. No-Calculator Simplified Method](#12-no-calculator-simplified-method)

---

## 0. Quick Start

### 30-Second Decision Flow

```text
1. ASSESS RISK    ‚Üí Select Level (L1-L5)
2. ACTIVATE       ‚Üí Choose experts by problem domain
3. INDEPENDENT    ‚Üí Each expert scores independently (Èò≤ÈîöÂÆö)
4. AGGREGATE      ‚Üí Enhanced formula: S_enhanced = S - ŒªœÉ
5. QUANTIFY       ‚Üí Output confidence interval + information sufficiency
6. DECIDE         ‚Üí Use enhanced decision rules
7. DOCUMENT       ‚Üí Use template from templates/EXPERT_COMMITTEE.md
```

### Level Quick Reference

| Problem Type | Level | Experts | Time |
|--------------|:-----:|:-------:|------|
| Bug fix, config | L1 | 2-3 | 15min |
| Minor feature, API | L2 | 4-6 | 30min |
| Refactor, new tech | L3 | 7-10 | 1h |
| Architecture, DB | L4 | 11-15 | 2-3h |
| Platform, security | L5 | 16-23 | Half day |

### Minimal Example (L1)

```markdown
**Decision**: Fix login button bug
**Panel**: Engineer, QA
**Angles**: A1 Correctness, D3 Clarity, D5 Testability
**Scores**: 5, 4, 5 ‚Üí S=4.7, œÉ=0.47, S_enhanced=4.47
**CI_95%**: [4.0, 4.9]
**Verdict**: Strong Approve (CI_lower > 3.5)
```

> Templates at `templates/EXPERT_COMMITTEE.md`

---

## 1. First Principles

### 1.1 Why Expert Committee?

| Problem | Solution |
|---------|----------|
| Single perspective ‚Üí blind spots | Multiple expert viewpoints |
| Ad-hoc quality checks | Structured angle evaluation |
| Static team composition | Dynamic activation by need |
| Overconfident decisions | Uncertainty quantification |
| Cognitive biases | Structural debiasing |

### 1.2 Core Philosophy

| Principle | Application |
|-----------|-------------|
| **‰ø° (Faithfulness)** | Correctness before elegance |
| **MECE** | Mutually exclusive, collectively exhaustive |
| **Dynamic** | Activate experts and angles on-demand |
| **Traceability** | Document all decisions and dissent |
| **Calibrated** | Output uncertainty, not just point estimates |

### 1.3 What This Framework Does

```text
Problem ‚Üí Select Level ‚Üí Activate Experts ‚Üí Independent Scoring ‚Üí 
Enhanced Aggregation ‚Üí Uncertainty Quantification ‚Üí Decide ‚Üí Document ‚Üí Feedback
```

---

## 2. Framework Overview

### 2.1 Component Summary

| Component | Count | Source (SSOT) |
|-----------|-------|---------------|
| Expert Domains | 6 | `ROLE_PERSONA.md` |
| Expert Roles | 23 | `ROLE_PERSONA.md` |
| Angle Categories | 10 | `DECISION.md` |
| Quality Angles | 37 | `DECISION.md` |
| Committee Levels | 5 | This document |

### 2.2 Expert Domains (6)

| Domain | Roles | Core Question |
|--------|-------|---------------|
| **Build** | 5 | How to implement correctly? |
| **Run** | 4 | How to operate reliably? |
| **Secure** | 3 | How to protect? |
| **Data** | 3 | How to manage data? |
| **Product** | 4 | How to satisfy users? |
| **Strategy** | 4 | How to create value? |

> Full details: `ROLE_PERSONA.md` Section 2-3

### 2.3 Angle Categories (10)

| Cat | Name | Angles | Core Question |
|-----|------|--------|---------------|
| A | Functional | 3 | Does it work correctly? |
| B | Reliability | 4 | Does it work consistently? |
| C | Performance | 3 | Is it fast enough? |
| D | Maintainability | 5 | Is it easy to change? |
| E | Portability | 3 | Can it be moved? |
| F | Security | 5 | Is it protected? |
| G | Compatibility | 2 | Does it integrate? |
| H | Usability | 6 | Is it user-friendly? |
| I | Data Quality | 3 | Is data trustworthy? |
| J | AI/ML Quality | 3 | Is AI reliable? |

> Full details: `DECISION.md` Section 2

---

## 3. Committee Levels

### 3.1 Level Definitions

| Level | Name | Experts | Angles | Time | Use Case |
|-------|------|---------|--------|------|----------|
| **L1** | Quick Check | 2-3 | 3 | 15 min | Low-risk, routine |
| **L2** | Standard | 4-6 | 12 | 30 min | Normal complexity |
| **L3** | Deep Analysis | 7-10 | 23 | 1 hour | Major changes |
| **L4** | Comprehensive | 11-15 | 31 | 2-3 hours | Critical decisions |
| **L5** | Full Committee | 16-23 | 37 | Half day | Strategic, org-wide |

### 3.2 Problem Type ‚Üí Level Mapping

| Problem Type | Level | Rationale |
|--------------|:-----:|-----------|
| Bug fix (isolated) | L1 | Low risk, easily reversible |
| Config change | L1 | Routine, single team |
| Minor feature | L2 | Normal complexity |
| API change (compatible) | L2 | Cross-team coordination |
| Significant refactoring | L3 | High impact, hard to reverse |
| New technology adoption | L3 | Department-wide impact |
| Architecture change | L4 | Critical, cross-department |
| Database migration | L4 | Very hard to reverse |
| Platform change | L5 | Strategic, org-wide |
| Security overhaul | L5 | Irreversible implications |

### 3.3 Level Selection Criteria

| Factor | L1 | L2 | L3 | L4 | L5 |
|--------|:--:|:--:|:--:|:--:|:--:|
| Risk | Low | Medium | High | Critical | Strategic |
| Reversibility | Easy | Moderate | Hard | Very Hard | Irreversible |
| Impact scope | 1 team | 2-3 teams | Department | Cross-dept | Org-wide |
| Stakeholders | 1-2 | 3-5 | 6-10 | 10-20 | 20+ |
| Cost impact | <$1K | $1K-$10K | $10K-$100K | $100K-$1M | >$1M |

### 3.4 Default Composition by Level

| Level | Build | Run | Secure | Data | Product | Strategy | Total |
|-------|:-----:|:---:|:------:|:----:|:-------:|:--------:|:-----:|
| L1 | 2-3 | - | - | - | - | - | 2-3 |
| L2 | 2-3 | 2 | - | - | 1 | - | 4-6 |
| L3 | 3-4 | 2-3 | 1-2 | 1 | 1-2 | - | 7-10 |
| L4 | 4 | 3 | 2 | 2 | 3 | 1 | 11-15 |
| L5 | 5 | 4 | 3 | 3 | 4 | 4 | 16-23 |

### 3.5 Default Angles by Level

| Level | Categories | Angles |
|-------|------------|--------|
| **L1** | A | A1-A3 (3) |
| **L2** | A, B, D | A1-A3, B1-B4, D1-D5 (12) |
| **L3** | A-F | A-F all (23) |
| **L4** | A-H | A-H all (31) |
| **L5** | A-J | All 37 |

### 3.6 Level Adjustment Factors

Higher committee levels require enhanced weight precision for critical decisions.

| Level | Factor | Effect | Rationale |
|-------|:------:|--------|-----------|
| **L1** | √ó1.00 | Baseline | Routine decisions |
| **L2** | √ó1.00 | Baseline | Standard decisions |
| **L3** | √ó1.05 | +5% | Major changes need higher precision |
| **L4** | √ó1.10 | +10% | Critical decisions amplify expert weight |
| **L5** | √ó1.15 | +15% | Strategic decisions maximize expert influence |

**Application Formula**:

```text
W_adjusted = W_total √ó Level_Factor

Where:
  W_total = 0.4 √ó W_domain + 0.6 √ó W_angle
  Level_Factor = {1.00, 1.00, 1.05, 1.10, 1.15} for L1-L5
```

**Example** (L4, Architect evaluating D1 in Build domain):

```text
W_domain = 0.9 (Architect-Build)
W_angle = 0.88 (Architect-D1, Primary)
W_total = 0.4 √ó 0.9 + 0.6 √ó 0.88 = 0.36 + 0.528 = 0.888
W_adjusted = 0.888 √ó 1.10 = 0.977
```

> **SSOT**: Weight values defined in `CONFLICT_RESOLUTION.md` Section 4.7

---

## 4. Dynamic Activation

### 4.1 Expert Activation Protocol

```text
1. IDENTIFY  ‚Üí Determine problem type and initial level
2. SELECT    ‚Üí Choose domains based on problem type
3. COMPOSE   ‚Üí Select specific roles from chosen domains
4. BRIEF     ‚Üí Present problem with context
5. ADJUST    ‚Üí Add/remove experts as analysis proceeds
6. DOCUMENT  ‚Üí Record final composition and rationale
```

### 4.2 Angle Activation Protocol

```text
1. START     ‚Üí Begin with level-default angles
2. ASSESS    ‚Üí Evaluate initial findings
3. EXPAND    ‚Üí Add categories if new concerns emerge
4. FOCUS     ‚Üí Remove irrelevant angles to save effort
5. COMPLETE  ‚Üí Ensure minimum coverage maintained
```

### 4.3 Activation Triggers

| Trigger | Expert Action | Angle Action |
|---------|---------------|--------------|
| Security concern | +Security, +Compliance | +F (Security) |
| Performance issue | +SRE, +DBA | +C (Performance) |
| User feedback | +UX, +Support | +H (Usability) |
| Data problem | +Data Eng, +Analyst | +I (Data Quality) |
| AI involved | +ML Eng | +J (AI/ML) |
| Strategic impact | +CTO, +Cost | +All relevant |

### 4.4 Constraints

| Rule | Expert | Angle |
|------|--------|-------|
| **Minimum** | 2 (L1) | A1 (Correctness) |
| **Maximum** | 23 (all) | 37 (all) |
| **Always include** | QA or Tech Lead | A1 |
| **Security-sensitive** | Security + Compliance | F1-F5 |
| **User-facing** | UX + PM | H1-H6 |

---

## 5. Analysis Process

### 5.1 Standard Workflow

```text
1. SCOPE      ‚Üí Define decision + select committee level
2. ASSEMBLE   ‚Üí Choose experts based on domains
3. ACTIVATE   ‚Üí Select angles based on level + problem type
4. BRIEF      ‚Üí Present problem with context
5. INDEPENDENT ‚Üí Each expert evaluates independently (NOÁúã‰ªñ‰∫∫)
6. COLLECT    ‚Üí Anonymous collection of scores
7. AGGREGATE  ‚Üí Apply enhanced aggregation formula
8. QUANTIFY   ‚Üí Calculate confidence interval + IS
9. DISCUSS    ‚Üí Share perspectives, identify conflicts (AFTER aggregation)
10. RESOLVE   ‚Üí Apply conflict resolution (see CONFLICT_RESOLUTION.md)
11. DECIDE    ‚Üí Use enhanced decision rules
12. DOCUMENT  ‚Üí Record decision + rationale + dissent
```

### 5.2 Scoring Scale

| Score | Meaning | Action |
|:-----:|---------|--------|
| 5 | Excellent | Proceed |
| 4 | Good | Minor improvements |
| 3 | Acceptable | Address concerns |
| 2 | Poor | Significant changes |
| 1 | Failing | Do not proceed |

---

## 6. Enhanced Aggregation

### 6.1 Basic Formula (Original)

```
S = Œ£(w·µ¢ √ó s·µ¢) / Œ£w·µ¢
```

### 6.2 Enhanced Formula (Required)

```
S_enhanced = S_weighted - Œª(n) √ó œÉ_corrected

Where:
- S_weighted = Œ£(w·µ¢ √ó s·µ¢) / Œ£w·µ¢           (weighted mean)
- œÉ_biased = ‚àö[Œ£w·µ¢(s·µ¢ - S)¬≤ / Œ£w·µ¢]        (biased weighted std dev)
- œÉ_corrected = œÉ_biased √ó ‚àö(n/(n-1))     (Bessel correction)
- Œª(n) = lookup from table below          (dynamic penalty coefficient)
```

### 6.3 Dynamic Œª(n) Lookup Table

| n (experts) | Œª(n) | No-Calculator Œª |
|:-----------:|:----:|:---------------:|
| 2-3 | 1.2 | 1.2 |
| 4-5 | 0.9 | 0.9 |
| 6-9 | 0.7 | 0.7 |
| 10-14 | 0.6 | 0.6 |
| 15-19 | 0.5 | 0.5 |
| ‚â•20 | 0.4 | 0.4 |

**Rationale**: Smaller samples have higher uncertainty; larger Œª provides more conservative estimates.

### 6.4 Bessel Correction Factor Table

| n (experts) | Factor ‚àö(n/(n-1)) | No-Calculator |
|:-----------:|:-----------------:|:-------------:|
| 2-3 | 1.3 | 1.3 |
| 4-5 | 1.15 | 1.15 |
| 6-10 | 1.1 | 1.1 |
| 11-15 | 1.05 | 1.05 |
| ‚â•16 | 1.0 | 1.0 |

**Rationale**: Corrects for bias in sample standard deviation estimation.

### 6.5 Calculation Example

**Scenario**: L2 decision, 4 experts

| Expert | Weight | Score |
|--------|--------|-------|
| Architect | 0.9 | 4 |
| Engineer | 0.7 | 4 |
| QA | 0.7 | 3 |
| PM | 0.3 | 5 |

**Step 1: Weighted Mean**
```
S = (0.9√ó4 + 0.7√ó4 + 0.7√ó3 + 0.3√ó5) / (0.9+0.7+0.7+0.3)
  = (3.6 + 2.8 + 2.1 + 1.5) / 2.6
  = 10.0 / 2.6 = 3.85
```

**Step 2: Weighted StdDev with Bessel Correction**
```
œÉ_biased = ‚àö[(0.9√ó0.02 + 0.7√ó0.02 + 0.7√ó0.72 + 0.3√ó1.32) / 2.6]
         = ‚àö[0.90 / 2.6] = 0.59

n = 4, Bessel factor = 1.15 (from table 6.4)
œÉ_corrected = 0.59 √ó 1.15 = 0.68
```

**Step 3: Enhanced Score with Dynamic Œª**
```
n = 4, Œª(4) = 0.9 (from table 6.3)
S_enhanced = 3.85 - 0.9 √ó 0.68 = 3.24
```

**Interpretation**: With corrected formulas, score is more conservative (3.24 vs 3.55 old method), better reflecting small-sample uncertainty.

### 6.6 Divergence Reference Table

| Corrected œÉ | Interpretation | Typical Penalty Range |
|-------------|----------------|----------------------|
| 0 - 0.3 | High consensus | Low |
| 0.3 - 0.6 | Minor divergence | Moderate |
| 0.6 - 1.0 | Moderate divergence | Significant |
| 1.0 - 1.5 | Significant divergence | High |
| > 1.5 | Severe divergence | Very High |

> **Note**: Actual penalty depends on Œª(n). Use `Penalty = Œª(n) √ó œÉ_corrected`.

---

## 7. Uncertainty Quantification

### 7.1 Confidence Interval (Corrected)

**Formula**:
```
CI_95% = [S_enhanced - t(n-1) √ó SE_corrected, S_enhanced + t(n-1) √ó SE_corrected]

Where:
- SE_basic = œÉ_corrected / ‚àön
- SE_corrected = SE_basic √ó ‚àö(1 + (n-1) √ó œÅ)   (correlation correction)
- t(n-1) = t-distribution value for df = n-1   (replaces z=1.96)
- œÅ = estimated correlation between experts    (from domain composition)
```

### 7.2 t-Distribution Lookup Table (95% CI)

| n (experts) | df | t_{0.975} | No-Calculator |
|:-----------:|:--:|:---------:|:-------------:|
| 2 | 1 | 12.71 | 12.7 |
| 3 | 2 | 4.30 | 4.3 |
| 4 | 3 | 3.18 | 3.2 |
| 5 | 4 | 2.78 | 2.8 |
| 6 | 5 | 2.57 | 2.6 |
| 7 | 6 | 2.45 | 2.5 |
| 8 | 7 | 2.36 | 2.4 |
| 10 | 9 | 2.26 | 2.3 |
| 15 | 14 | 2.14 | 2.1 |
| 20 | 19 | 2.09 | 2.1 |
| ‚â•25 | 24+ | ~2.0 | 2.0 |

**No-Calculator Simplified**:

| n | Use t = |
|---|:-------:|
| 2-3 | 4.0 |
| 4-5 | 3.0 |
| 6-9 | 2.4 |
| 10-14 | 2.2 |
| 15-19 | 2.1 |
| ‚â•20 | 2.0 |

### 7.3 Correlation Estimation Table

| Domain Composition | Estimated œÅ | SE Multiplier ‚àö(1+(n-1)œÅ) for n=10 |
|--------------------|:-----------:|:----------------------------------:|
| All different domains | 0.05 | 1.2 |
| 25% same domain | 0.10 | 1.4 |
| 50% same domain | 0.15 | 1.6 |
| 75% same domain | 0.25 | 1.8 |
| All same domain | 0.35 | 2.1 |

**No-Calculator Simplified**:
| Composition | SE √ó |
|-------------|:----:|
| Mixed domains | 1.3 |
| Majority same domain | 1.7 |
| All same domain | 2.0 |

### 7.4 Calculation Example (continued from 6.5)

```
From Section 6.5: S_enhanced = 3.24, œÉ_corrected = 0.68, n = 4

Step 1: Basic SE
SE_basic = 0.68 / ‚àö4 = 0.34

Step 2: Correlation Correction (assume mixed domains, œÅ ‚âà 0.10)
SE_corrected = 0.34 √ó ‚àö(1 + 3√ó0.10) = 0.34 √ó 1.14 = 0.39

Step 3: t-Distribution CI (n=4, t=3.18)
CI_95% = [3.24 - 3.18√ó0.39, 3.24 + 3.18√ó0.39]
       = [3.24 - 1.24, 3.24 + 1.24]
       = [2.00, 4.48]
```

**Comparison with old method**:
| Method | CI_95% | CI Width |
|--------|--------|:--------:|
| Old (z=1.96, no corrections) | [2.97, 4.13] | 1.16 |
| **New (t-dist, corrected)** | [2.00, 4.48] | 2.48 |

> **Interpretation**: Corrected CI is wider, honestly reflecting small-sample uncertainty.

### 7.5 Enhanced Decision Rules

| Condition | Decision | Action |
|-----------|----------|--------|
| CI_lower > 3.5 | **Strong Approve** | Proceed confidently |
| S > 3.5 AND CI_lower > 2.5 | **Conditional Approve** | Proceed with monitoring |
| CI_upper < 2.5 | **Strong Reject** | Do not proceed |
| CI_width > 2.0 | **Need More Info** | Add experts or discuss |
| Other | **Revise** | Re-evaluate after changes |

### 7.6 Information Sufficiency (IS)

```
IS = max(0, 1 - (CI_width / 4))    # Lower bound at 0

IS > 0.7   ‚Üí Information sufficient
IS 0.5-0.7 ‚Üí Basically sufficient
IS < 0.5   ‚Üí Insufficient, add more experts
IS = 0     ‚Üí Extreme uncertainty, defer decision
```

**Example** (continued from 7.4):
```
CI_width = 4.48 - 2.00 = 2.48
IS = max(0, 1 - (2.48 / 4)) = max(0, 0.38) = 0.38
‚Üí Insufficient information, add more experts or discuss
```

> **Note**: With corrected formulas, small samples often yield IS < 0.5, correctly signaling need for more experts.

---

## 8. Bias Correction

### 8.1 Three-Step Debiasing Process

```text
Step 1: Independent Scoring (prevents anchoring)
        ‚Üì
Step 2: Anonymous Aggregation (prevents conformity)
        ‚Üì
Step 3: Open Discussion (information sharing)
```

### 8.2 Implementation Requirements

| Phase | Requirement | Reason |
|-------|-------------|--------|
| **Independent Scoring** | Each expert scores without seeing others | Prevent anchoring effect |
| **Anonymous Aggregation** | Show statistics first, not who scored what | Prevent authority suppression |
| **Open Discussion** | Discuss divergence points, allow score revision | Full information sharing |

### 8.3 Random Speaking Order

```python
# Randomize expert speaking order for each decision
import random
experts = ["Architect", "Engineer", "QA", "PM", ...]
random.shuffle(experts)  # Randomize
```

### 8.4 Devil's Advocate Requirements

Each decision **MUST** include:

| Requirement | Count | Assignment Method |
|-------------|-------|-------------------|
| Dissenting opinion | ‚â•1 | Rotate or assign Risk role |
| Risk enumeration | ‚â•3 | Each expert contributes ‚â•1 |
| Alternative approach | ‚â•1 | Lowest-scoring expert proposes |

---

## 9. Dynamic Weight Learning

### 9.1 Lightweight Implementation

Simple **sliding window accuracy** instead of complex Bayesian updates:

```
Dynamic Weight = Base Weight √ó Accuracy Adjustment

Accuracy Adjustment = (Correct in last 10 decisions + 5) / 15
```

### 9.2 Example

| Expert | Base Weight | Last 10 Correct | Adjustment | Dynamic Weight |
|--------|-------------|-----------------|------------|----------------|
| Architect | 0.9 | 8 | (8+5)/15=0.87 | 0.78 |
| Engineer | 0.7 | 9 | (9+5)/15=0.93 | 0.65 |
| QA | 0.7 | 10 | (10+5)/15=1.0 | 0.70 |

### 9.3 Cold Start Handling

New experts or new domains: Use base weight, start adjusting after 5 accumulated decisions.

---

## 10. Decision Effectiveness Tracking

### 10.1 Post-Decision Review

| Checkpoint | Timing | Question |
|------------|--------|----------|
| **Immediate** | 1 week | Was implementation smooth? |
| **Short-term** | 1 month | Did expected benefits materialize? |
| **Long-term** | 3 months | Was the decision correct? |

### 10.2 Effectiveness Metrics

| Metric | Formula | Target |
|--------|---------|:------:|
| Decision Accuracy | Correct / Total | >85% |
| Prediction Error | \|Predicted - Actual\| | <20% |
| Reversal Rate | Reversed / Total | <10% |
| Calibration | CI coverage rate | >90% |

### 10.3 Feedback Loop

```text
1. RECORD   ‚Üí Document decision with predictions
2. SCHEDULE ‚Üí Set review checkpoints
3. COMPARE  ‚Üí Actual vs predicted outcomes
4. LEARN    ‚Üí Update weights if systematic errors
```

### 10.4 Review Template

| Item | Predicted | Actual | Delta | Lesson |
|------|-----------|--------|:-----:|--------|
| Outcome | | | | |
| Timeline | | | | |
| Risk Events | | | | |
| User Impact | | | | |

### 10.5 Continuous Improvement

| Signal | Action |
|--------|--------|
| Accuracy <85% | Review angle coverage |
| Prediction Error >20% | Calibrate expert weights |
| Reversal Rate >10% | Increase committee level |
| CI coverage <90% | Adjust Œª parameter |
| Systematic bias | Add/remove expert roles |

---

## 11. Quick Reference

### 11.1 Level Selection Guide

| Question | L1 | L2 | L3 | L4 | L5 |
|----------|:--:|:--:|:--:|:--:|:--:|
| Can we easily undo? | ‚úì | ‚úì | ¬∑ | ¬∑ | ¬∑ |
| Affects only 1 team? | ‚úì | ‚úì | ¬∑ | ¬∑ | ¬∑ |
| Low security risk? | ‚úì | ‚úì | ‚úì | ¬∑ | ¬∑ |
| Under $10K impact? | ‚úì | ‚úì | ‚úì | ¬∑ | ¬∑ |
| Reversible in <1 day? | ‚úì | ‚úì | ¬∑ | ¬∑ | ¬∑ |

### 11.2 Domain Selection by Problem

| Problem | Primary Domains |
|---------|-----------------|
| Architecture | Build, Strategy |
| Feature | Build, Product |
| Security | Secure, Run |
| Performance | Run, Build |
| Data | Data, Secure |
| Operations | Run |

### 11.3 Summary Statistics

| Metric | Value |
|--------|-------|
| Expert Domains | 6 |
| Expert Roles | 23 |
| Angle Categories | 10 |
| Quality Angles | 37 |
| Committee Levels | 5 |
| Max Matrix Size | 23 √ó 37 = 851 |

### 11.4 Quick Enhancement Checklist

```markdown
‚ñ° Independent scoring? (prevents anchoring)
‚ñ° Applied Bessel correction to œÉ? (œÉ_corrected = œÉ_biased √ó factor from ¬ß6.4)
‚ñ° Used dynamic Œª(n) from table ¬ß6.3? (not fixed 0.5)
‚ñ° Applied divergence penalty? (S_enhanced = S - Œª(n) √ó œÉ_corrected)
‚ñ° Used t-distribution for CI? (not z=1.96, see ¬ß7.2)
‚ñ° Applied correlation correction to SE? (see ¬ß7.3)
‚ñ° Output confidence interval? (uncertainty quantification)
‚ñ° Information sufficiency > 0.5? (IS = max(0, 1 - CI_width/4))
‚ñ° Devil's advocate opinion? (structural debiasing)
```

---

## 12. No-Calculator Simplified Method

> For situations where calculators or spreadsheets are unavailable. Accuracy: ~90% of full method.

### 12.1 Simplified Weight System

Replace decimal weights with integer tiers:

| Original Weight | Simplified Tier | Multiplier |
|-----------------|-----------------|:----------:|
| 0.9 (Primary expertise) | **High** | 3 |
| 0.6-0.7 (Secondary) | **Medium** | 2 |
| 0.2-0.5 (Minimal) | **Low** | 1 |

### 12.2 Quick Score Calculation

**Step 1**: Assign tier multipliers and collect scores

| Expert | Tier | Score |
|--------|:----:|:-----:|
| Expert A | 3 | s‚Çê |
| Expert B | 2 | s·µ¶ |
| Expert C | 1 | s·µß |

**Step 2**: Calculate weighted average (integer math)

```
S = (3√ós‚Çê + 2√ós·µ¶ + 1√ós·µß) / (3+2+1)
```

**Step 3**: Calculate divergence penalty (with dynamic Œª)

```
Range = max(scores) - min(scores)
Œª = lookup from simplified table below
Penalty = Œª √ó Range / 4
S_final = S - Penalty
```

**Simplified Œª(n) for No-Calculator**:
| n (experts) | Œª |
|:-----------:|:-:|
| 2-3 | 1.2 |
| 4-5 | 0.9 |
| 6-9 | 0.7 |
| ‚â•10 | 0.5 |

### 12.3 Range-Based Divergence Table

| Score Range | œÉ Approximation | Penalty (√∑5) | Interpretation |
|:-----------:|:---------------:|:------------:|----------------|
| 0 | ~0 | 0 | Perfect consensus |
| 1 | ~0.4 | 0.2 | Minor divergence |
| 2 | ~0.8 | 0.4 | Moderate divergence |
| 3 | ~1.2 | 0.6 | Significant divergence |
| 4 | ~1.6 | 0.8 | Severe divergence |

### 12.4 Quick Decision Matrix

| S_final | Range ‚â§1 | Range = 2 | Range ‚â•3 |
|:--------|:---------|:----------|:---------|
| **‚â•4.0** | ‚úÖ Strong Approve | ‚ö†Ô∏è Conditional | üîÑ Discuss First |
| **3.5-3.9** | ‚ö†Ô∏è Conditional | üîÑ Revise | üîÑ Revise |
| **3.0-3.4** | üîÑ Revise | üîÑ Revise | ‚ùå Reject |
| **<3.0** | ‚ùå Reject | ‚ùå Reject | ‚ùå Reject |

### 12.5 Information Sufficiency Quick Check

| Expert Count | Range ‚â§1 | Range = 2 | Range ‚â•3 |
|:-------------|:---------|:----------|:---------|
| **‚â•5** | ‚úÖ Sufficient | ‚úÖ Sufficient | ‚ö†Ô∏è Borderline |
| **3-4** | ‚úÖ Sufficient | ‚ö†Ô∏è Borderline | ‚ùå Insufficient |
| **2** | ‚ö†Ô∏è Borderline | ‚ùå Insufficient | ‚ùå Insufficient |

### 12.6 ‚àön Lookup Table (for CI calculation if needed)

| n (experts) | ‚àön | 2/‚àön (CI factor) |
|:-----------:|:--:|:----------------:|
| 2 | 1.4 | 1.4 |
| 3 | 1.7 | 1.2 |
| 4 | 2.0 | 1.0 |
| 5 | 2.2 | 0.9 |
| 6 | 2.4 | 0.8 |
| 8 | 2.8 | 0.7 |
| 10 | 3.2 | 0.6 |
| 15 | 3.9 | 0.5 |
| 20 | 4.5 | 0.4 |

**Simplified CI**: `CI ‚âà [S_final - Factor√óRange/2, S_final + Factor√óRange/2]`

### 12.7 Complete No-Calculator Example

**Scenario**: L2 decision with 4 experts

| Expert | Tier | Score |
|--------|:----:|:-----:|
| Architect | 3 | 4 |
| Engineer | 2 | 4 |
| QA | 2 | 3 |
| PM | 1 | 5 |

**Calculation**:
```
Sum of weights = 3 + 2 + 2 + 1 = 8
Weighted sum = 3√ó4 + 2√ó4 + 2√ó3 + 1√ó5 = 12 + 8 + 6 + 5 = 31
S = 31 / 8 = 3.875 ‚âà 3.9

Range = 5 - 3 = 2
n = 4, Œª = 0.9 (from simplified table)
Penalty = 0.9 √ó 2 / 4 = 0.45
S_final = 3.9 - 0.45 = 3.45

Decision: S_final=3.45, Range=2 ‚Üí "Revise" (from matrix)
Info Sufficiency: 4 experts, Range=2 ‚Üí "Borderline"
```

**Compare to full method**: S_enhanced=3.24, reasonably close!

### 12.8 One-Page Cheat Sheet

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  NO-CALCULATOR EXPERT COMMITTEE CHEAT SHEET v2.2    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. WEIGHTS: High=3, Medium=2, Low=1                ‚îÇ
‚îÇ  2. AVERAGE: S = Œ£(tier√óscore) / Œ£(tier)            ‚îÇ
‚îÇ  3. DYNAMIC Œª: 2-3 experts‚Üí1.2, 4-5‚Üí0.9, 6-9‚Üí0.7,   ‚îÇ
‚îÇ                ‚â•10‚Üí0.5                              ‚îÇ
‚îÇ  4. PENALTY: Œª √ó Range / 4                          ‚îÇ
‚îÇ  5. FINAL: S_final = S - Penalty                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  QUICK DECISION:                                    ‚îÇ
‚îÇ  ‚Ä¢ S‚â•4 + Range‚â§1 ‚Üí Approve                          ‚îÇ
‚îÇ  ‚Ä¢ S‚â•3.5 + Range‚â§1 ‚Üí Conditional                    ‚îÇ
‚îÇ  ‚Ä¢ S<3 or Range‚â•3 ‚Üí Reject/Discuss                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  INFO CHECK:                                        ‚îÇ
‚îÇ  ‚Ä¢ ‚â•5 experts + Range‚â§2 ‚Üí Sufficient                ‚îÇ
‚îÇ  ‚Ä¢ 3-4 experts + Range‚â§1 ‚Üí Sufficient               ‚îÇ
‚îÇ  ‚Ä¢ Otherwise ‚Üí Add more experts                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  CI QUICK (if needed):                              ‚îÇ
‚îÇ  ‚Ä¢ t-value: n‚â§3‚Üí4, n=4-5‚Üí3, n=6-9‚Üí2.4, n‚â•10‚Üí2.2     ‚îÇ
‚îÇ  ‚Ä¢ CI ‚âà S ¬± t √ó Range / (2√ó‚àön)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Related

- `.knowledge/templates/EXPERT_COMMITTEE_QUICKSTART.md` ‚Äî **Quick-Start Guide (5 min)**
- `.knowledge/templates/EXPERT_COMMITTEE.md` ‚Äî Decision templates
- `.knowledge/frameworks/cognitive/ROLE_PERSONA.md` ‚Äî Expert roles (SSOT)
- `.knowledge/frameworks/patterns/DECISION.md` ‚Äî Quality angles (SSOT)
- `.knowledge/frameworks/cognitive/CONFLICT_RESOLUTION.md` ‚Äî Conflict resolution
- `.knowledge/guidelines/COGNITIVE.md` ‚Äî Cognitive guidelines

---

*Expert Committee Framework v2.2*
